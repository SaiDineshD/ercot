{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB4_dgM2tmz5"
      },
      "source": [
        "# ERCOT Energy Market Intelligence – Google Colab\n",
        "\n",
        "**Real-time demand forecasting & anomaly detection for the Texas ERCOT grid**\n",
        "\n",
        "Run this notebook on [Google Colab](https://colab.research.google.com) for free GPU.\n",
        "\n",
        "1. Clone the repo\n",
        "2. Install dependencies\n",
        "3. Add your EIA API key (get one at https://www.eia.gov/opendata/)\n",
        "4. Run all cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTMPedYbtmz8"
      },
      "outputs": [],
      "source": [
        "# Run this first: Setup (clone if needed)\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/YOUR_USERNAME/ercot-market-intelligence.git\"  # ← Update with your repo\n",
        "\n",
        "if not os.path.exists(\"models\"):\n",
        "    !git clone {REPO_URL} ercot-repo\n",
        "    os.chdir(\"ercot-repo\")\n",
        "\n",
        "!pip install -q torch pandas numpy scikit-learn xgboost requests matplotlib seaborn\n",
        "print(\"Setup complete. CWD:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN2q_c1otmz-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import xgboost as xgb\n",
        "\n",
        "from models.data_pipeline import (\n",
        "    fetch_grid_load,\n",
        "    fetch_weather,\n",
        "    fetch_forecast,\n",
        "    engineer_features,\n",
        "    prepare_gnn_dataset,\n",
        ")\n",
        "from models.gnn_forecaster import train_gnn_forecaster, predict_gnn\n",
        "from models.gnn_anomaly import train_gnn_ae, detect_anomalies_gnn\n",
        "\n",
        "# EIA API key: paste here, or use Colab Secrets (Keychain icon → Add EIA_API_KEY)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    EIA_API_KEY = userdata.get('EIA_API_KEY')\n",
        "except:\n",
        "    EIA_API_KEY = \"YOUR_EIA_API_KEY\"  # ← Replace with your key from https://www.eia.gov/opendata/\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "print(\"Environment ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_ReDZzgtmz-"
      },
      "source": [
        "## 1. Fetch Real ERCOT + Weather Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MBXTO8ctmz_"
      },
      "outputs": [],
      "source": [
        "print(\"Fetching ERCOT grid load...\")\n",
        "df_grid = fetch_grid_load(EIA_API_KEY)\n",
        "\n",
        "start = df_grid.index.min().strftime('%Y-%m-%d')\n",
        "end = (df_grid.index.max() - pd.Timedelta(days=5)).strftime('%Y-%m-%d')\n",
        "print(f\"Fetching weather for {start} to {end}...\")\n",
        "df_weather = fetch_weather(start=start, end=end)\n",
        "\n",
        "df_raw = df_grid.join(df_weather, how='inner')\n",
        "df_forecast = fetch_forecast(EIA_API_KEY)\n",
        "if not df_forecast.empty:\n",
        "    df_raw = df_raw.join(df_forecast, how='inner')\n",
        "\n",
        "df_model = engineer_features(df_raw)\n",
        "print(f\"Data ready: {len(df_model)} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEB3ItZltmz_"
      },
      "source": [
        "## 2. Prepare GNN Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIZHGO_stmz_"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test, feature_names, adj = prepare_gnn_dataset(\n",
        "    df_model, target_col='load_mw', seq_len=24, horizon=1, train_ratio=0.85\n",
        ")\n",
        "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "print(f\"Features: {feature_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww2JWlFjtm0A"
      },
      "source": [
        "## 3. XGBoost Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVNsXoSitm0A"
      },
      "outputs": [],
      "source": [
        "features = [f for f in ['hour', 'day_of_week', 'is_weekend', 'temperature_2m', 'load_lag_1h', 'load_lag_24h'] if f in df_model.columns]\n",
        "split = int(len(df_model) * 0.85)\n",
        "train_df, test_df = df_model.iloc[:split], df_model.iloc[split:]\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, early_stopping_rounds=20)\n",
        "xgb_model.fit(train_df[features], train_df['load_mw'], eval_set=[(test_df[features], test_df['load_mw'])], verbose=False)\n",
        "xgb_pred = xgb_model.predict(test_df[features])\n",
        "xgb_mape = mean_absolute_percentage_error(test_df['load_mw'], xgb_pred)\n",
        "print(f\"XGBoost MAPE: {xgb_mape:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GhiL22ztm0A"
      },
      "source": [
        "## 4. GNN Forecaster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YzmYgSqtm0B"
      },
      "outputs": [],
      "source": [
        "gnn_model, gnn_losses, scale_params = train_gnn_forecaster(\n",
        "    X_train, y_train, adj, epochs=20, batch_size=128\n",
        ")\n",
        "gnn_pred = predict_gnn(gnn_model, X_test, scale_params=scale_params)\n",
        "gnn_mape = mean_absolute_percentage_error(y_test, gnn_pred)\n",
        "print(f\"GNN MAPE: {gnn_mape:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn2y6rqktm0B"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "n_show = min(168, len(y_test))\n",
        "plt.plot(y_test[:n_show], label='Actual', linewidth=2)\n",
        "plt.plot(gnn_pred[:n_show], label='GNN', linestyle='--')\n",
        "plt.plot(xgb_pred[:n_show], label='XGBoost', linestyle='--', alpha=0.8)\n",
        "plt.title('ERCOT Load Forecast')\n",
        "plt.ylabel('Load (MW)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SS7zOmKtm0B"
      },
      "source": [
        "## 5. Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv1wYGSwtm0B"
      },
      "outputs": [],
      "source": [
        "anomaly_features = [f for f in ['load_mw', 'temperature_2m', 'grid_stress'] if f in df_model.columns]\n",
        "iso = IsolationForest(contamination=0.02, random_state=42)\n",
        "df_model['iso_anomaly'] = iso.fit_predict(df_model[anomaly_features])\n",
        "iso_count = (df_model['iso_anomaly'] == -1).sum()\n",
        "\n",
        "ae_model, _ = train_gnn_ae(X_train, adj, epochs=15, batch_size=128)\n",
        "_, mask, _ = detect_anomalies_gnn(ae_model, X_test, threshold_percentile=98)\n",
        "gnn_anomalies = mask.sum()\n",
        "\n",
        "print(f\"Isolation Forest: {iso_count} anomalies\")\n",
        "print(f\"GNN AutoEncoder: {gnn_anomalies} test anomalies\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxggt5UKtm0B"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*50)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"XGBoost MAPE: {xgb_mape:.2%}\")\n",
        "print(f\"GNN MAPE:     {gnn_mape:.2%}\")\n",
        "print(f\"Anomalies: IF={iso_count}, GNN={gnn_anomalies}\")\n",
        "print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}